{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ea0cd2",
   "metadata": {},
   "source": [
    "# NLP with Deep Learning Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7b156-4162-41f6-960e-7e970662d404",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd051b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31309f7",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7dc6a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: [\"former versace store clerk sues over secret 'black code' for minority shoppers\", \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\", \"mom starting to fear son's web series closest thing she will have to grandchild\", 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas', 'j.k. rowling wishes snape happy birthday in the most magical way']\n",
      "\n",
      "\n",
      "Labels: [0, 0, 1, 1, 0]\n",
      "\n",
      "\n",
      "URLs: ['https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365', 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697', 'https://politics.theonion.com/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302', 'https://www.huffingtonpost.com/entry/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "urls = []\n",
    "\n",
    "with open(\"Sarcasm_Headlines_Dataset.json\", 'r') as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        sentences.append(item['headline'])\n",
    "        labels.append(item['is_sarcastic'])\n",
    "        urls.append(item['article_link'])\n",
    "\n",
    "print(\"Sentences:\", sentences[:5])\n",
    "print('\\n')\n",
    "print(\"Labels:\", labels[:5])\n",
    "print('\\n')\n",
    "print(\"URLs:\", urls[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c35b2-7b59-4640-ad41-f93252307696",
   "metadata": {},
   "source": [
    "### Data Preprocessing (Tokenize and get word index, Create Sequences and Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d8fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data so the neural network doesn't see the test data\n",
    "training_size = 20000\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c41e15-79ae-4499-bc88-02669e00bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming these are our variables\n",
    "vocab_size = 27000  # Adjust according to your vocabulary size\n",
    "embedding_dim = 100\n",
    "maxlen = 100  # Adjust according to your maximum sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130d16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<00V>\")\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "#Splitting and padding the training set\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, padding='post')\n",
    "\n",
    "#Splitting and padding the test set\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bace1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to array\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17813b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ade6aa-d69c-4c3c-b786-5600c37021b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idris\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 - 29s - 46ms/step - accuracy: 0.7780 - loss: 0.4538 - val_accuracy: 0.8495 - val_loss: 0.3487\n",
      "Epoch 2/30\n",
      "625/625 - 18s - 29ms/step - accuracy: 0.9280 - loss: 0.1890 - val_accuracy: 0.8419 - val_loss: 0.3788\n",
      "Epoch 3/30\n",
      "625/625 - 17s - 28ms/step - accuracy: 0.9820 - loss: 0.0547 - val_accuracy: 0.8399 - val_loss: 0.5249\n",
      "Epoch 4/30\n",
      "625/625 - 18s - 29ms/step - accuracy: 0.9922 - loss: 0.0226 - val_accuracy: 0.8414 - val_loss: 0.7135\n",
      "Epoch 5/30\n",
      "625/625 - 17s - 28ms/step - accuracy: 0.9948 - loss: 0.0157 - val_accuracy: 0.8454 - val_loss: 0.7455\n",
      "Epoch 6/30\n",
      "625/625 - 18s - 29ms/step - accuracy: 0.9967 - loss: 0.0098 - val_accuracy: 0.8351 - val_loss: 0.9253\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the improved model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(training_padded, training_labels, epochs=30, validation_data=(testing_padded, testing_labels), verbose=2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e1fbe",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32240c55-7d4b-4f23-bd07-ddc51bfe6a41",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "### Model Evaluation: Conv1D with Global Max Pooling, Dropout, and Early StoppiMy\r\n",
    "This model utilizes a Conv1D architecture with Global Max Pooling and Dropout layers, combined with early stopping to prevent overfitting. The model was trained for 6 epochs out of the planned 30 due to early stopping, which halted the training when the validation loss failed to improve.\r\n",
    "\r\n",
    "### Breakdown of Your Code\r\n",
    "\r\n",
    "1. **Importing Libraries:**\r\n",
    "```python\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Conv1D, GlobalMaxPooling1D\r\n",
    "from tensorflow.keras.callbacks import EarlyStopping\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "```\r\n",
    "\r\n",
    "2. **Defining the Model:**\r\n",
    "```python\r\n",
    "model = Sequential()\r\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\r\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\r\n",
    "model.add(GlobalMaxPooling1D())\r\n",
    "model.add(Dropout(0.5))\r\n",
    "model.add(Dense(128, activation='relu'))\r\n",
    "model.add(Dropout(0.5))\r\n",
    "model.add(Dense(1, activation='sigmoid'))\r\n",
    "```\r\n",
    "\r\n",
    "- **Sequential()**: Initializes the model as a linear stack of layers.\r\n",
    "- **Embedding**: Converts integer indices into dense vectors of fixed size (`embedding_dim`). This layer helps capture the semantic meaning of words.\r\n",
    "- **Conv1D(filters=128, kernel_size=5, activation='relu')**: A 1D convolutional layer with 128 filters and a kernel size of 5, applying the ReLU activation function. This layer detects local features in the sequence data.\r\n",
    "- **GlobalMaxPooling1D()**: Reduces the dimensionality by taking the maximum value across the time steps, allowing the model to focus on the most prominent features detected by the convolutional layers.\r\n",
    "- **Dropout(0.5)**: Randomly sets 50% of the input units to 0 during training, which helps prevent overfitting.\r\n",
    "- **Dense(128, activation='relu')**: A fully connected layer with 128 units and ReLU activation to learn complex patterns in the data.\r\n",
    "- **Dense (Output Layer)**: A fully connected layer with 1 unit and sigmoid activation, outputting a probability score between 0 and 1 for binary classification.\r\n",
    "\r\n",
    "3. **Compiling the Model:**\r\n",
    "```python\r\n",
    "optimizer = Adam(learning_rate=0.001)\r\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\r\n",
    "```\r\n",
    "\r\n",
    "- **optimizer='Adam'**: Adam optimizer with a learning rate of 0.001, which adaptively adjusts learning rates for different parameters.\r\n",
    "- **loss='binary_crossentropy'**: This loss function is used for binary classification tasks.\r\n",
    "- **metrics=['accuracy']**: Accuracy is monitored during training and validation.\r\n",
    "\r\n",
    "4. **Early Stopping Callback:**\r\n",
    "```python\r\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\r\n",
    "```\r\n",
    "\r\n",
    "- **EarlyStopping**: Monitors the validation loss and stops training if it doesn't improve for 5 consecutive epochs. The best weights are restored after stopping.\r\n",
    "\r\n",
    "5. **Training the Model:**\r\n",
    "```python\r\n",
    "history = model.fit(training_padded, training_labels, epochs=30, validation_data=(testing_padded, testing_labels), verbose=2, callbacks=[early_stopping])\r\n",
    "```\r\n",
    "\r\n",
    "- **fit**: Trains the model for a maximum of 30 epochs, but early stopping may terminate training early.\r\n",
    "- **validation_data**: The model's performance is evaluated on the validation data at the end of each epoch.\r\n",
    "- **callbacks**: Early stopping is used to monitor and potentially interrupt the training process early.\r\n",
    "\r\n",
    "### Explanation of Results\r\n",
    "\r\n",
    "1. **Epoch 1/30:**\r\n",
    "   - **accuracy: 0.7780** and **loss: 0.4538**: The model starts with 77.80% accuracy on the training data and a loss of 0.4538.\r\n",
    "   - **val_accuracy: 0.8495** and **val_loss: 0.3487**: The validation performance is better, with an accuracy of 84.95% and a loss of 0.3487, suggesting that the model is learning effectively.\r\n",
    "\r\n",
    "2. **Epoch 2/30:**\r\n",
    "   - **accuracy: 0.9280** and **loss: 0.1890**: The training accuracy increases significantly to 92.80%, and the loss decreases, indicating that the model is effectively learning patterns in the training data.\r\n",
    "   - **val_accuracy: 0.8419** and **val_loss: 0.3788**: Vd the validation loss increases, suggesting the beginning of overfitting.\r\n",
    "\r\n",
    "3. **Epoch 3/30:**\r\n",
    "   - **accuracy: 0.9820** and **loss: 0.0547*er, reaching 98.20%, with a low loss, but this is indicative of overfitting.\r\n",
    "   - **val_accuracy: 0.8399** and **val_loss: 0.5249**: The validation loss increases, confirming that the model is overfitting to the training data.\r\n",
    "\r\n",
    "4. **Epoch 4/30:**\r\n",
    "   - **accuracy: 0.9922** and **loss: 0.0226**: The model continues to perform exceptionally well on the training data with very low loss, further suggesting overfitting.\r\n",
    "   - **val_accurarease, indicating that the model is not generalizing well to the validation data.\r\n",
    "\r\n",
    "5. **Epoch 5/30:**\r\n",
    "   - **accuracy: 0.9948** and **loss: 0.0157**: The model's performance on the training data is nearly perfect, which is a clear sign of overfitting.\r\n",
    "   - **val_accuracy: 0.8454** and **val_loss: 0.7455**:  validation accuracy, but the loss continues to rise, further confirming overfitting.\r\n",
    "\r\n",
    "6. **Epoch 6/30:**\r\n",
    "   - **accuracy: 0.9967** and **loss: 0.0098**: The model's training accuracy is almost 100%, with minimal loss.\r\n",
    "   - **val_accuracy: 0.8351** and **va e dropout rates, reducing the model's complexity, or increasing the amount of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2599d78-bf48-459d-b61d-dd45bb89692b",
   "metadata": {},
   "source": [
    "**Testing on new sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "557872c7-bd02-4313-9cdf-67ecb71a85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"Oh great, another Monday morning meeting. Can't wait.\",  # Sarcastic\n",
    "    \"I had a wonderful time at the park today with my friends.\"  # Not sarcastic\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb29872",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sequences = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e32c8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(new_sequences, maxlen = maxlen,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2db38c7-3e08-4c1b-a866-c8113e04e750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "[[0.84157  ]\n",
      " [0.1560598]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255fdf1-7639-462d-a79c-9e047bce8231",
   "metadata": {},
   "source": [
    "**Comparing with test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "342b53c6-5182-48a9-b836-be091da881a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testing_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6930acde-62df-4b84-ac60-54031e8091b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8494559546877329\n",
      "Precision: 0.8312629399585921\n",
      "Recall: 0.822184300341297\n",
      "F1 Score: 0.8266986959505833\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Example sigmoid outputs (probabilities) from your model\n",
    "sigmoid_outputs = predictions\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold of 0.5\n",
    "threshold = 0.5\n",
    "binary_predictions = (sigmoid_outputs > threshold).astype(int)\n",
    "\n",
    "# Example test labels\n",
    "test_labels = testing_labels\n",
    "\n",
    "# Evaluate the predictions\n",
    "accuracy = accuracy_score(test_labels, binary_predictions)\n",
    "precision = precision_score(test_labels, binary_predictions)\n",
    "recall = recall_score(test_labels, binary_predictions)\n",
    "f1 = f1_score(test_labels, binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3460d7",
   "metadata": {},
   "source": [
    "# Let's try using an LSTM layer (Long Short Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c725ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming these are your variables\n",
    "vocab_size = 27000  # Adjust according to your vocabulary size\n",
    "embedding_dim = 100\n",
    "maxlen = 100  # Adjust according to your maximum sequence length\n",
    "\n",
    "# Create and pad sequences\n",
    "training_padded = pad_sequences(training_sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "training_padded = np.array(training_padded)\n",
    "testing_padded = np.array(testing_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bd4ec77-a5fe-4344-9969-f067b1ceca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idris\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 - 147s - 235ms/step - accuracy: 0.5015 - loss: 6.2891 - val_accuracy: 0.5509 - val_loss: 5.1404 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "625/625 - 90s - 144ms/step - accuracy: 0.5153 - loss: 4.9184 - val_accuracy: 0.5604 - val_loss: 4.2336 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "625/625 - 95s - 152ms/step - accuracy: 0.5188 - loss: 4.1127 - val_accuracy: 0.5570 - val_loss: 3.6580 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "625/625 - 95s - 151ms/step - accuracy: 0.5247 - loss: 3.5504 - val_accuracy: 0.6148 - val_loss: 3.1952 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "625/625 - 93s - 149ms/step - accuracy: 0.5404 - loss: 3.0869 - val_accuracy: 0.6786 - val_loss: 2.7860 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "625/625 - 90s - 144ms/step - accuracy: 0.5987 - loss: 2.6509 - val_accuracy: 0.7737 - val_loss: 2.3462 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "625/625 - 91s - 146ms/step - accuracy: 0.7324 - loss: 2.1945 - val_accuracy: 0.8202 - val_loss: 1.9178 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "625/625 - 89s - 143ms/step - accuracy: 0.8487 - loss: 1.7614 - val_accuracy: 0.8417 - val_loss: 1.6129 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "625/625 - 90s - 144ms/step - accuracy: 0.9092 - loss: 1.3952 - val_accuracy: 0.8396 - val_loss: 1.4237 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "625/625 - 145s - 232ms/step - accuracy: 0.9405 - loss: 1.1072 - val_accuracy: 0.8360 - val_loss: 1.2438 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "625/625 - 93s - 149ms/step - accuracy: 0.9609 - loss: 0.8740 - val_accuracy: 0.8386 - val_loss: 1.1182 - learning_rate: 9.0484e-05\n",
      "Epoch 12/30\n",
      "625/625 - 93s - 149ms/step - accuracy: 0.9723 - loss: 0.6989 - val_accuracy: 0.8356 - val_loss: 1.0823 - learning_rate: 8.1873e-05\n",
      "Epoch 13/30\n",
      "625/625 - 90s - 145ms/step - accuracy: 0.9786 - loss: 0.5733 - val_accuracy: 0.8302 - val_loss: 1.0186 - learning_rate: 7.4082e-05\n",
      "Epoch 14/30\n",
      "625/625 - 90s - 145ms/step - accuracy: 0.9826 - loss: 0.4792 - val_accuracy: 0.8301 - val_loss: 1.0069 - learning_rate: 6.7032e-05\n",
      "Epoch 15/30\n",
      "625/625 - 97s - 155ms/step - accuracy: 0.9872 - loss: 0.4051 - val_accuracy: 0.8334 - val_loss: 0.9652 - learning_rate: 6.0653e-05\n",
      "Epoch 16/30\n",
      "625/625 - 91s - 146ms/step - accuracy: 0.9888 - loss: 0.3530 - val_accuracy: 0.8343 - val_loss: 0.9376 - learning_rate: 5.4881e-05\n",
      "Epoch 17/30\n",
      "625/625 - 91s - 145ms/step - accuracy: 0.9922 - loss: 0.3044 - val_accuracy: 0.8344 - val_loss: 0.9418 - learning_rate: 2.4829e-05\n",
      "Epoch 18/30\n",
      "625/625 - 90s - 144ms/step - accuracy: 0.9945 - loss: 0.2725 - val_accuracy: 0.8346 - val_loss: 0.9490 - learning_rate: 1.1233e-05\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "\n",
    "# Bidirectional LSTM layers with L2 regularization\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(0.01))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(0.01))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Bidirectional(LSTM(32, kernel_regularizer=l2(0.01))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Dense layer with L2 regularization\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping with a more conservative patience value\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Reduce learning rate on plateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=0.00001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    training_padded, \n",
    "    training_labels, \n",
    "    epochs=30, \n",
    "    validation_data=(testing_padded, testing_labels), \n",
    "    callbacks=[early_stopping, reduce_lr, lr_scheduler], \n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41469c-72cf-4975-8844-ec499e2f9354",
   "metadata": {},
   "source": [
    "# Evaluate your new model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06edbe-7d10-4135-b686-df72fa3d3403",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "### Model Evaluation: Bidirectional LSTM with Batch Normalization, Dropout, and Learning Rate Scheduling\r\n",
    "\r\n",
    "This model employs a Bidirectional LSTM architecture with Batch Normalization, Dropout regularization, L2 regularization, and advanced learning rate scheduling. The model is designed to combat overfitting and improve generalization. The training lasted for 18 epochs out of the planned 30 due to the early stopping mechanism.\r\n",
    "\r\n",
    "### Breakdown of Your Code\r\n",
    "\r\n",
    "1. **Importing Libraries:**\r\n",
    "```python\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense, BatchNormalization\r\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras.regularizers import l2\r\n",
    "```\r\n",
    "\r\n",
    "2. **Defining the Model:**\r\n",
    "```python\r\n",
    "model = Sequential()\r\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\r\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(0.01))))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Dropout(0.6))\r\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(0.01))))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Dropout(0.6))\r\n",
    "model.add(Bidirectional(LSTM(32, kernel_regularizer=l2(0.01))))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Dropout(0.6))\r\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\r\n",
    "model.add(Dropout(0.6))\r\n",
    "model.add(Dense(1, activation='sigmoid'))\r\n",
    "```\r\n",
    "\r\n",
    "- **Sequential()**: Initializes a linear stack of layers.\r\n",
    "- **Embedding**: Converts integer indices into dense vectors of a fixed size (`embedding_dim`), capturing the semantic meaning of words.\r\n",
    "- **Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(0.01)))**: LSTM layers that process input sequences bidirectionally, with L2 regularization to penalize large weights.\r\n",
    "- **BatchNormalization()**: Normalizes the output of the LSTM layers to stabilize learning.\r\n",
    "- **Dropout(0.6)**: Randomly sets 60% of the input units to 0, helping to prevent overfitting.\r\n",
    "- **Dense(32, activation='relu', kernel_regularizer=l2(0.01))**: A fully connected layer with ReLU activation and L2 regularization to learn complex patterns.\r\n",
    "- **Dense (Output Layer)**: A fully connected layer with 1 unit and sigmoid activation for binary classification.\r\n",
    "\r\n",
    "3. **Compiling the Model:**\r\n",
    "```python\r\n",
    "optimizer = Adam(learning_rate=0.0001)\r\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\r\n",
    "```\r\n",
    "\r\n",
    "- **optimizer='Adam'**: An adaptive learning rate optimizer that adjusts learning rates for different parameters.\r\n",
    "- **loss='binary_crossentropy'**: A loss function for binary classification.\r\n",
    "- **metrics=['accuracy']**: Monitors accuracy during training and validation.\r\n",
    "\r\n",
    "4. **Callbacks for Training:**\r\n",
    "```python\r\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\r\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=0.00001)\r\n",
    "\r\n",
    "def scheduler(epoch, lr):\r\n",
    "    if epoch < 10:\r\n",
    "        return lr\r\n",
    "    else:\r\n",
    "        return float(lr * tf.math.exp(-0.1))\r\n",
    "\r\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\r\n",
    "```\r\n",
    "\r\n",
    "- **EarlyStopping**: Stops training if the validation loss does not improve for 2 consecutive epochs, restoring the best weights.\r\n",
    "- **ReduceLROnPlateau**: Reduces the learning rate by a factor of 0.5 if the validation loss plateaus, with a minimum learning rate of 0.00001.\r\n",
    "- **LearningRateScheduler**: Decreases the learning rate exponentially after 10 epochs to fine-tune the learning process.\r\n",
    "\r\n",
    "5. **Training the Model:**\r\n",
    "```python\r\n",
    "history = model.fit(training_padded, training_labels, epochs=30, validation_data=(testing_padded, testing_labels), callbacks=[early_stopping, reduce_lr, lr_scheduler], verbose=2)\r\n",
    "```\r\n",
    "\r\n",
    "- **fit**: Trains the model for a maximum of 30 epochs, with early stopping potentially terminating the training early.\r\n",
    "- **validation_data**: Evaluates the model’s performance on the validation set after each epoch.\r\n",
    "- **callbacks**: Incorporates early stopping, learning rate reduction, and scheduling to optimize training.\r\n",
    "\r\n",
    "### Explanation of Results\r\n",
    "\r\n",
    "1. **Epoch 1/30:**\r\n",
    "   - **accuracy: 0.5015** and **loss: 6.2891**: The model starts with 50.15% accuracy and a high loss, suggesting it's initially struggling to learn.\r\n",
    "   - **val_accuracy: 0.5509** and **val_loss: 5.1404**: The validation metrics show slight improvement, indicating the model is beginning to learn.\r\n",
    "\r\n",
    "2. **Epoch 6/30:**\r\n",
    "   - **accuracy: 0.5987** and **loss: 2.6509**: The model’s performance improves, achieving 59.87% accuracy with a reduced loss, indicating it is learning more effectively.\r\n",
    "   - **val_accuracy: 0.7737** and **val_loss: 2.3462**: Validation accuracy improves significantly, suggesting that the model is generalizing better.\r\n",
    "\r\n",
    "3. **Epoch 10/30:**\r\n",
    "   - **accuracy: 0.9405** and **loss: 1.1072**: The model achieves over 94% accuracy on training data, but this high accuracy suggests potential overfitting.\r\n",
    "   - **val_accuracy: 0.8360** and **val_loss: 1.2438**: The validation loss starts to increase slightly, hinting at the beginning of overfitting.\r\n",
    "\r\n",
    "4. **Epoch 18/30:**\r\n",
    "   - **accuracy: 0.9945** and **loss: 0.2725**: The model reaches near-perfect accuracy on the training set, strongly indicating overfitting.\r\n",
    "   - **val_accuracy: 0.8346** and **val_loss: 0.9490**: Va as reducing the model's complexity or increasing the dropout rate, could help improve generalization.hniques, more data, or tuning the model architecture to improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dce53b-23ab-4cbd-b09e-17c14479b600",
   "metadata": {},
   "source": [
    "**Comparing with test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77e6bcb1-e7a5-4c0e-9aa5-7edf206e85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 115ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testing_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b246add4-d8b5-4031-8f85-4a64babaee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.834252496646296\n",
      "Precision: 0.844579226686884\n",
      "Recall: 0.7604095563139932\n",
      "F1 Score: 0.8002873563218392\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Example sigmoid outputs (probabilities) from your model\n",
    "sigmoid_outputs = predictions\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold of 0.5\n",
    "threshold = 0.5\n",
    "binary_predictions = (sigmoid_outputs > threshold).astype(int)\n",
    "\n",
    "# Example test labels\n",
    "test_labels = testing_labels\n",
    "\n",
    "# Evaluate the predictions\n",
    "accuracy = accuracy_score(test_labels, binary_predictions)\n",
    "precision = precision_score(test_labels, binary_predictions)\n",
    "recall = recall_score(test_labels, binary_predictions)\n",
    "f1 = f1_score(test_labels, binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef635678-baad-4c95-be3d-07f83eac4e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8639141451781189\n",
      "Precision: 0.859536541889483\n",
      "Recall: 0.8228668941979522\n",
      "F1 Score: 0.8408020924149955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Example sigmoid outputs (probabilities) from your model\n",
    "sigmoid_outputs = predictions\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold of 0.5\n",
    "threshold = 0.5\n",
    "binary_predictions = (sigmoid_outputs > threshold).astype(int)\n",
    "\n",
    "# Example test labels\n",
    "test_labels = testing_labels\n",
    "\n",
    "# Evaluate the predictions\n",
    "accuracy = accuracy_score(test_labels, binary_predictions)\n",
    "precision = precision_score(test_labels, binary_predictions)\n",
    "recall = recall_score(test_labels, binary_predictions)\n",
    "f1 = f1_score(test_labels, binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43179cf",
   "metadata": {},
   "source": [
    "# Building a model that can write poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "592b4599-ca49-43d5-a20b-d993c7608b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = \"\"\"\n",
    "In twilight's gentle, fleeting grace,\n",
    "A wanderer roams the open space,\n",
    "His steps a whisper on the ground,\n",
    "Where shadows play and dreams are found.\n",
    "\n",
    "With every stride, the earth's embrace,\n",
    "Turns ancient tales in twilight's face,\n",
    "A saddle tight, his spirit free,\n",
    "He seeks the stars, the boundless sea.\n",
    "\n",
    "Yet as he wanders, time stands still,\n",
    "The night reveals its subtle thrill,\n",
    "He watches skies with eyes of fire,\n",
    "For constellations, dreams aspire.\n",
    "\n",
    "In moonlit silence, tales unwind,\n",
    "Of distant lands and love entwined,\n",
    "His journey ends where starlight gleams,\n",
    "In echoes of forgotten dreams.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "006b1bc2-391b-4bde-aece-51119a116e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = poem.lower().split('/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "12dbfd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "052207f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "89a859e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25645"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "49a3fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in poem:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f3725fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 6847],\n",
       " [5, 6847, 5122],\n",
       " [5, 6847, 5122, 8650],\n",
       " [5, 6847, 5122, 8650, 3346],\n",
       " [5, 6847, 5122, 8650, 3346, 7],\n",
       " [5, 6847, 5122, 8650, 3346, 7, 12785],\n",
       " [5, 6847, 5122, 8650, 3346, 7, 12785, 7934],\n",
       " [5, 6847, 5122, 8650, 3346, 7, 12785, 7934, 4],\n",
       " [5, 6847, 5122, 8650, 3346, 7, 12785, 7934, 4, 363],\n",
       " [5, 6847, 5122, 8650, 3346, 7, 12785, 7934, 4, 363, 836],\n",
       " [5, 6847, 5122, 8650, 3346, 7, 12785, 7934, 4, 363, 836, 33],\n",
       " [5, 6847, 5122, 8650, 3346, 7, 12785, 7934, 4, 363, 836, 33, 974],\n",
       " [5, 6847, 5122, 8650, 3346, 7, 12785, 7934, 4, 363, 836, 33, 974, 7],\n",
       " [5, 6847, 5122, 8650, 3346, 7, 12785, 7934, 4, 363, 836, 33, 974, 7, 12786],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504,\n",
       "  1087],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504,\n",
       "  1087,\n",
       "  158],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504,\n",
       "  1087,\n",
       "  158,\n",
       "  8875],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504,\n",
       "  1087,\n",
       "  158,\n",
       "  8875,\n",
       "  12790],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504,\n",
       "  1087,\n",
       "  158,\n",
       "  8875,\n",
       "  12790,\n",
       "  5],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504,\n",
       "  1087,\n",
       "  158,\n",
       "  8875,\n",
       "  12790,\n",
       "  5,\n",
       "  5780],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504,\n",
       "  1087,\n",
       "  158,\n",
       "  8875,\n",
       "  12790,\n",
       "  5,\n",
       "  5780,\n",
       "  3],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504,\n",
       "  1087,\n",
       "  158,\n",
       "  8875,\n",
       "  12790,\n",
       "  5,\n",
       "  5780,\n",
       "  3,\n",
       "  2015],\n",
       " [5,\n",
       "  6847,\n",
       "  5122,\n",
       "  8650,\n",
       "  3346,\n",
       "  7,\n",
       "  12785,\n",
       "  7934,\n",
       "  4,\n",
       "  363,\n",
       "  836,\n",
       "  33,\n",
       "  974,\n",
       "  7,\n",
       "  12786,\n",
       "  8,\n",
       "  4,\n",
       "  1217,\n",
       "  158,\n",
       "  5650,\n",
       "  578,\n",
       "  9,\n",
       "  807,\n",
       "  30,\n",
       "  268,\n",
       "  10,\n",
       "  142,\n",
       "  6833,\n",
       "  4,\n",
       "  3324,\n",
       "  3045,\n",
       "  700,\n",
       "  1808,\n",
       "  2905,\n",
       "  5,\n",
       "  6847,\n",
       "  273,\n",
       "  7,\n",
       "  8868,\n",
       "  5448,\n",
       "  33,\n",
       "  2235,\n",
       "  260,\n",
       "  34,\n",
       "  2155,\n",
       "  4,\n",
       "  716,\n",
       "  4,\n",
       "  8688,\n",
       "  1108,\n",
       "  453,\n",
       "  27,\n",
       "  34,\n",
       "  8671,\n",
       "  57,\n",
       "  2282,\n",
       "  73,\n",
       "  4,\n",
       "  254,\n",
       "  293,\n",
       "  189,\n",
       "  6801,\n",
       "  3617,\n",
       "  34,\n",
       "  4241,\n",
       "  12787,\n",
       "  10,\n",
       "  845,\n",
       "  3,\n",
       "  297,\n",
       "  6,\n",
       "  12788,\n",
       "  807,\n",
       "  12789,\n",
       "  5,\n",
       "  8500,\n",
       "  1309,\n",
       "  2905,\n",
       "  6507,\n",
       "  3,\n",
       "  3181,\n",
       "  2100,\n",
       "  9,\n",
       "  136,\n",
       "  7643,\n",
       "  33,\n",
       "  1504,\n",
       "  1087,\n",
       "  158,\n",
       "  8875,\n",
       "  12790,\n",
       "  5,\n",
       "  5780,\n",
       "  3,\n",
       "  2015,\n",
       "  807]]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4232a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ef6d2162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    5, 6847],\n",
       "       [   0,    0,    0, ...,    5, 6847, 5122],\n",
       "       [   0,    0,    0, ..., 6847, 5122, 8650],\n",
       "       ...,\n",
       "       [   0,    0,    5, ...,    5, 5780,    3],\n",
       "       [   0,    5, 6847, ..., 5780,    3, 2015],\n",
       "       [   5, 6847, 5122, ...,    3, 2015,  807]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f11f2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "67de69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into features and labels (the last feature in evey row becomes a lable)\n",
    "xs = input_sequences[:,:-1]\n",
    "labels = input_sequences[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8232b153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     0,     0,     5],\n",
       "       [    0,     0,     0, ...,     0,     5,  6847],\n",
       "       [    0,     0,     0, ...,     5,  6847,  5122],\n",
       "       ...,\n",
       "       [    0,     0,     5, ..., 12790,     5,  5780],\n",
       "       [    0,     5,  6847, ...,     5,  5780,     3],\n",
       "       [    5,  6847,  5122, ...,  5780,     3,  2015]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b5332512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6847],\n",
       "       [ 5122],\n",
       "       [ 8650],\n",
       "       [ 3346],\n",
       "       [    7],\n",
       "       [12785],\n",
       "       [ 7934],\n",
       "       [    4],\n",
       "       [  363],\n",
       "       [  836],\n",
       "       [   33],\n",
       "       [  974],\n",
       "       [    7],\n",
       "       [12786],\n",
       "       [    8],\n",
       "       [    4],\n",
       "       [ 1217],\n",
       "       [  158],\n",
       "       [ 5650],\n",
       "       [  578],\n",
       "       [    9],\n",
       "       [  807],\n",
       "       [   30],\n",
       "       [  268],\n",
       "       [   10],\n",
       "       [  142],\n",
       "       [ 6833],\n",
       "       [    4],\n",
       "       [ 3324],\n",
       "       [ 3045],\n",
       "       [  700],\n",
       "       [ 1808],\n",
       "       [ 2905],\n",
       "       [    5],\n",
       "       [ 6847],\n",
       "       [  273],\n",
       "       [    7],\n",
       "       [ 8868],\n",
       "       [ 5448],\n",
       "       [   33],\n",
       "       [ 2235],\n",
       "       [  260],\n",
       "       [   34],\n",
       "       [ 2155],\n",
       "       [    4],\n",
       "       [  716],\n",
       "       [    4],\n",
       "       [ 8688],\n",
       "       [ 1108],\n",
       "       [  453],\n",
       "       [   27],\n",
       "       [   34],\n",
       "       [ 8671],\n",
       "       [   57],\n",
       "       [ 2282],\n",
       "       [   73],\n",
       "       [    4],\n",
       "       [  254],\n",
       "       [  293],\n",
       "       [  189],\n",
       "       [ 6801],\n",
       "       [ 3617],\n",
       "       [   34],\n",
       "       [ 4241],\n",
       "       [12787],\n",
       "       [   10],\n",
       "       [  845],\n",
       "       [    3],\n",
       "       [  297],\n",
       "       [    6],\n",
       "       [12788],\n",
       "       [  807],\n",
       "       [12789],\n",
       "       [    5],\n",
       "       [ 8500],\n",
       "       [ 1309],\n",
       "       [ 2905],\n",
       "       [ 6507],\n",
       "       [    3],\n",
       "       [ 3181],\n",
       "       [ 2100],\n",
       "       [    9],\n",
       "       [  136],\n",
       "       [ 7643],\n",
       "       [   33],\n",
       "       [ 1504],\n",
       "       [ 1087],\n",
       "       [  158],\n",
       "       [ 8875],\n",
       "       [12790],\n",
       "       [    5],\n",
       "       [ 5780],\n",
       "       [    3],\n",
       "       [ 2015],\n",
       "       [  807]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f7e6a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e1307afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(total_words, 240, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3d9e45c1-d98f-4687-ad44-60137d60aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 358ms/step - accuracy: 0.0236 - loss: 10.1108\n",
      "Epoch 2/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.0589 - loss: 6.8573\n",
      "Epoch 3/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - accuracy: 0.0222 - loss: 4.8044\n",
      "Epoch 4/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - accuracy: 0.0053 - loss: 4.5723  \n",
      "Epoch 5/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - accuracy: 0.0353 - loss: 4.5168\n",
      "Epoch 6/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - accuracy: 0.0353 - loss: 4.4491\n",
      "Epoch 7/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.0876 - loss: 4.2182\n",
      "Epoch 8/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - accuracy: 0.0812 - loss: 4.1713\n",
      "Epoch 9/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - accuracy: 0.0355 - loss: 4.0191\n",
      "Epoch 10/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step - accuracy: 0.0511 - loss: 3.7714\n",
      "Epoch 11/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - accuracy: 0.1674 - loss: 3.4302\n",
      "Epoch 12/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - accuracy: 0.2851 - loss: 3.1667\n",
      "Epoch 13/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.2683 - loss: 2.9224\n",
      "Epoch 14/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - accuracy: 0.4174 - loss: 2.5797\n",
      "Epoch 15/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.5218 - loss: 2.2441\n",
      "Epoch 16/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - accuracy: 0.6032 - loss: 1.9002\n",
      "Epoch 17/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - accuracy: 0.6373 - loss: 1.6797\n",
      "Epoch 18/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - accuracy: 0.7210 - loss: 1.3267\n",
      "Epoch 19/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - accuracy: 0.8558 - loss: 1.0983\n",
      "Epoch 20/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step - accuracy: 0.8037 - loss: 0.9393\n",
      "Epoch 21/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - accuracy: 0.8703 - loss: 0.7366\n",
      "Epoch 22/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - accuracy: 0.8506 - loss: 0.5732\n",
      "Epoch 23/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - accuracy: 0.8925 - loss: 0.4904\n",
      "Epoch 24/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - accuracy: 0.9214 - loss: 0.4174\n",
      "Epoch 25/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - accuracy: 0.9280 - loss: 0.4086\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(xs, ys, epochs=25, batch_size=32, verbose=1,  callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3c4f1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"In the hush of dawn, a wanderer\"\n",
    "next_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "db9e0db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the hush of dawn, a wanderer roams\n",
      "In the hush of dawn, a wanderer roams the\n",
      "In the hush of dawn, a wanderer roams the ground\n",
      "In the hush of dawn, a wanderer roams the ground where\n",
      "In the hush of dawn, a wanderer roams the ground where starlight\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer roams\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer roams the\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer roams the ground\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer roams the ground where\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer roams the ground where starlight\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer roams the ground where starlight gleams\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer roams the ground where starlight gleams in\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer roams the ground where starlight gleams in twilight's\n",
      "In the hush of dawn, a wanderer roams the ground where starlight gleams in twilight's face a wanderer roams the ground where starlight gleams in twilight's face\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    predicted_index = np.argmax(predicted_probs, axis=-1)[0]\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "    print(seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f47fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5d3be-a323-40b3-b939-904407c101c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
